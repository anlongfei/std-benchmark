\documentclass{sig-alternate}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{graphviz}
\usepackage{auto-pst-pdf}
\usepackage{etoolbox}
\usepackage{flushend}
\usepackage{needspace}

\makeatletter
\preto{\@verbatim}{\topsep=1pt \partopsep=0pt}
\makeatother

\pagenumbering{arabic}

\begin{document}
\def \GCC {GCC}
\def \LLVM {LLVM}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\title{Benchmarking C/C++ standard libraries}

\toappear{
   \hrule \vspace{5pt}
   Some conf
}
\numberofauthors{3}

\author{
\alignauthor
Aditya Kumar\\
       \affaddr{Samsung Austin R\&D Center}\\
       \email{aditya.k7@samsung.com}
\and
\alignauthor
Sebastian\\
       \affaddr{Samsung Austin R\&D Center}\\
       \email{ancd}
}

\maketitle
\begin{abstract}
We present a systematic analysis of C and C++ standard libraries. The goal here
is to enable each programmer make informed decision about the functionality one
is using and not just rely on common wisdom. We make it very easy to know the
internals of the standard libraries. There are benchmark analyses available
online but those are in bits and pieces. We present a comprehensize
infrastructure where a large subset of standard library is covered. This also
enables someone to run their own configuration of test by adding just few lines
of code. This also allows the programmer to compare which compiler toolchain
generates better code in terms of performance, code-size etc. such that they can
choose the right toolchain for their application. The comparative analysis of
multiple toolchains also enabled us to improve the underperforming library
functions.
\end{abstract}

\section{Introduction}
Although programmers use C++ mostly in performance critical applications,
there is little literature to validate claims on how C++ programs perform
better than programs written in other languages. Early work by M{\"u}ller \cite{muller}
and the technical report on C++ performance \cite{c++perftr} give some
perspective on this. Since that time, compilers and hardware have come a long way
and there is a need to revisit this. Moreover, a systematic analysis of C++ standard libraries
has not been done with great rigor. Some references on gcc mailing list show
analysis of basic\_string etc but after the conclusion ended in a suboptimal
implementation.

Why a systematic analysis is important.

The main contributions of this paper are:
\begin{itemize}
\item a benchmark suite for C/C++ standard library
\item ability to compare compiler performance for standard libraries
\item identifying slower implementation in standard library
\item investigating whether C++11/14 really makes your code faster (for
standard libraries) at -O0, -O3
\item investigating which nuances of C++ standard causes suboptimal
implementation of programs
\end{itemize}

\section{Related Work}
Several bits and pieces of benchmarking available online.  Bjarne's channel9
talk \cite{stroustrup2012}.  He talks about std::list vs. std::vector, in fact
there are several analyses online, all of them establish std::vector as a better
choice over std::list. But is std::vector the best sequential data structure?
Our experiments indicate that std::deque may be better in many cases
\ref{sec:experiments}.

clrs \cite{clrs}
C++ standard \cite{c++fcd}

\newpage

\subsection{Layout of the project}
Structure

\subsection{Illustrative Example} \label{subsec:example}
How to add a single benchmark \cite{googlebench}
\newpage


\section{Performance problems due to C++ standardese}
char\_traits<char>::find has to check if both the pointer to the string and the
number of characters to analyze, because if both are zero then the result is
valid (zero).



\begin{verbatim}
static const char_type*
find(const char_type* __s, size_t __n, const char_type& __a)
{
  if (__n == 0)
    return 0;
  return memchr(__s, __a, __n);
}
\end{verbatim}

A pointer to the first character in the range specified by [p, p + count) that
  compares equal to ch, or NULL if not found.


size being an unsigned int. Many loops written in C++ have unsigned integers
as induction variables, the problem is that unsigned int overflow is well
defined so the compiler cannot assume that loop is monotonic. This disables
many useful compiler optimizations like vectorization etc.
TODO: Example??

Undefined behavior
http://stackoverflow.com/a/367662/811335

\section{Experimental Results and discussion}
\label{sec:experiments}

\subsection{Benchmark results comparison across toolchains}

\subsection{Time complexity results}

\subsection{C vs C++ algorithms}
string::find vs. strstr.

We present the results we got on x86-64 as well as aarch64 machines.

\section{compiler vs programmer}
We created test to figure out simple patterns which could be converted to
standard library functions by the compiler but did not in some cases. This is
mostly because of aliasing ambiguities and how the programmer can void them.  In
the benchmark compiler.vs.programmer/memory.bench.cpp, we have program like:

\begin{verbatim}
const char* __attribute__ ((noinline))
assign(const char *beg, const char *end, char *dest) {
  while (beg != end)
    *dest++ = *beg++;
  return beg;
}
\end{verbatim}

This is a very common pattern found in many codebases including C++ standard
libraries e.g., libcxx:locale.cpp:const char*ctype<char>::do\_widen,

\begin{verbatim}
const char*
ctype<char>::do_widen(const char* low, const char* high,
                      char_type* dest) const
{
    for (; low != high; ++low, ++dest)
        *dest = *low;
    return low;
}
\end{verbatim}

The dest never aliases with the low or the high pointer but the compiler fails
to convert this to memcpy, because it cannot figure out low, high, and dest are
not aliases of each other.  It might be able to figure out if they were inlined
in the caller but this function is in a .cpp file and hence the caller will not
see it. This function gets called over and over again each time you invoke
std::stringstream to parse token of integers from a character stream.

Just adding \_\_restrict\_\_ would solve this problem, for example in the
function assign\_res
from\\ std-benchmark/compiler.vs.programmer/memory.bench.cpp there is another
function which shows the usage in this case.

\begin{verbatim}
const char* __attribute__ ((noinline))
assign_res(const char * __restrict__ beg,
           const char * __restrict__ end,
           char *__restrict__ dest) {
  while (beg != end)
    *dest++ = *beg++;
  return beg;
}
\end{verbatim}

This function runs twice as fast as the one without restrict.

\begin{verbatim}
Benchmark                        Time   Iterations
--------------------------------------------------
BM_prog_memcpy/32                5 ns    143049157
BM_prog_memcpy/64                6 ns    117543415
BM_prog_memcpy/128               8 ns     87350103
BM_prog_memcpy/256              12 ns     57677864
BM_prog_memcpy/512              20 ns     34332565
BM_prog_memcpy/1024             36 ns     19396612
BM_compiler_memcpy/32            4 ns    181115627
BM_compiler_memcpy/64            4 ns    169701384
BM_compiler_memcpy/128           6 ns    111126103
BM_compiler_memcpy/256           6 ns    122750774
BM_compiler_memcpy/512           8 ns     91138876
BM_compiler_memcpy/1024         11 ns     62055274
BM_memcpy/32                     3 ns    246831272
BM_memcpy/64                     3 ns    226251314
BM_memcpy/128                    6 ns    124278117
BM_memcpy/256                    5 ns    150856758
BM_memcpy/512                    6 ns    114059692
BM_memcpy/1024                  10 ns     69498277
\end{verbatim}


; MSVC compiler identification is:  MSVC 19.10.25019.0
; Same machine was used for gcc, clang, and MSVC (using dual boot)
MSVC Compiler size of containers (64 bit):
Sizeof, std::deque<int>(), 40
	_Mapptr _Map;		// pointer to array of pointers to blocks
	size_type _Mapsize;	// size of map array, zero or 2^N
	size_type _Myoff;	// offset of initial element
	size_type _Mysize;	// current length of sequence


Sizeof, std::list<int>(), 16
 (node ptr and size only)

Sizeof, std::vector<int>(), 24
	pointer _Myfirst;	// pointer to beginning of array
	pointer _Mylast;	// pointer to current end of sequence
	pointer _Myend;	// pointer to end of array

Sizeof, std::set<int>(), 16
Sizeof, (std::map<int, int>()), 16
	_Nodeptr _Myhead;	// pointer to head node
	size_type _Mysize;	// number of elements


Sizeof, (std::unordered_map<int, int>()), 64
Sizeof, std::unordered_set<int>(), 64
	_Traits _Traitsobj;	// traits to customize behavior
	_Mylist _List;	// list of elements, must initialize before _Vec
	_Myvec _Vec;	// vector of list iterators, begin() then end()-1
	size_type _Mask;	// the key mask
	size_type _Maxidx;	// current maximum key value


\section{Timing and Limitations}
Timing and Limitations
\subsection{Limitations of the time-complexity measurement}

\section{Conclusion and Future Work}

\bibliographystyle{abbrv}
{\small
\bibliography{Bibliography}
}
\end{document}
